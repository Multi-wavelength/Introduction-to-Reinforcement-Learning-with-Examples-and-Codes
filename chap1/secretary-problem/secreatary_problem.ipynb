{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "problem_description",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "-scxVrBr79BY"
      },
      "source": [
        "# Chapter 1 Dynamic Programming and Bellman Equations\n",
        "\n",
        "\n",
        "## Example: Secretary Problem\n",
        "\n",
        "In this example, we will solve the secretary problem using stochastic dynamic programming (DP).\n",
        "\n",
        "### Secretary Problem\n",
        "\n",
        "The secretary problem [1] can be described as follows. Imagine an administrator who wants to hire the best secretary out of $n$ available candidates. They are interviewed in succession in random order, that is, for each interview the administrator picks a candidate uniformly at random from the remaining candidates. After interviewing the $h^{\\mathrm{th}}$ candidate, the administrator knows the ranking of the $h^{\\mathrm{th}}$ candidate among the candidates interviewed so far, but is unaware of the quality of unseen candidates. The administrator needs to determine whether to hire or reject the $h^{\\mathrm{th}}$ candidate immediately after the interview. Note that the administrator cannot go back to hire candidate $1,\\ldots,h-1$ after interviewing the $h^{\\mathrm{th}}$ candidate. At most one candidate can be hired. The goal is to maximize the probability of hiring the best candidate.\n",
        "\n",
        "### Problem Formulation\n",
        "\n",
        "We can formulate the secretary problem into a finite-horizon stochastic DP problem as follows:\n",
        "\n",
        "- Stage $h$: the time when the administrator makes decision after interviewing the $h^{\\mathrm{th}}$ candidate. $h\\in\\{1,...,n\\}$.\n",
        "    \n",
        "- State $s_h$: the ranking of the $h^{\\mathrm{th}}$ candidate among the candidates interviewed so far. $s_h\\in\\{1,...,h\\}$.\n",
        "\n",
        "    Define a terminal state $g$ such that if the administrator has already hired one candidate in one of the previous interviews, then $s_{h}=g, s_{h+1}=g,\\ldots,s_{n}=g$. That is, once the administrator decides to hire a candidate, the process will go to the terminal state and remain in the terminal state.\n",
        "\n",
        "- Action $a_h$:\n",
        "    \n",
        "  If $s_h\\neq g$, then\n",
        "\n",
        "  - $a_h=1$ means hiring the $h^{\\mathrm{th}}$ candidate;\n",
        "  - $a_h=0$ means rejecting the $h^{\\mathrm{th}}$ candidate.\n",
        "\n",
        "  If $s_h=g$, then the only available action is $a_h=0$, meaning rejecting the $h^{\\mathrm{th}}$ candidate, because $s_h=g$ means that the administrator has already hired one candidate previously.\n",
        "    \n",
        "- Reward $r_h(s_h,a_h)$: \n",
        "    \n",
        "    $r_h(s_h,a_h)=1$ if $s_h\\neq g$, $a_h=1$ and the $h^{\\mathrm{th}}$ candidate is the best candidate among all the $n$ candidates. \n",
        "    \n",
        "    Otherwise, $r_h(s_h,a_h)=0$.\n",
        "    \n",
        "    Note that if $s_h\\neq 1$, $r_h(s_h,1)=0$ because $s_h\\neq 1$ means that the $h^{\\mathrm{th}}$ candidate is not the best among the $h$ candidates that have been interviewed and of course not the best among all candidates. If $s_h=1$, we can calculate the probability that the $h^{\\mathrm{th}}$ candidate is the best among all candidates as follows:\n",
        "\n",
        "    \\begin{align*}\n",
        "        \\Pr\\left(\\mbox{the $h^{\\mathrm{th}}$ candidate is the best among all candidates}|s_h=1\\right)=\\frac{{n-1 \\choose h-1} (h-1)!(n-h)!}{{n \\choose h} (h-1)!(n-h)!}=\\frac{h}{n}.\n",
        "    \\end{align*}\n",
        "\n",
        "    Therefore, $r_h(1,1)=1$ with probability $h/n$.\n",
        "    \n",
        "- Transition probabilities:\n",
        "    \n",
        "    For any $m\\in\\{1,\\ldots,h+1\\}$ and $k\\in\\{1,\\ldots,h\\}$, we have\n",
        "\n",
        "    \\begin{align*}\n",
        "        \\Pr(s_{h+1}=m|s_h=k,a_h=0)=\\frac{{n \\choose h+1} (h-1)!(n-h-1)!}{{n \\choose h+1} {h+1 \\choose h}(h-1)!(n-h-1)!}=\\frac{1}{h+1},\n",
        "    \\end{align*}\n",
        "\n",
        "    which means that $s_{h+1}$ will be uniformly distributed in $\\{1,\\ldots,h+1\\}$ if $s_h\\neq g$ and $a_h=0$. And for any $k\\in\\{1,\\ldots,h\\}$,\n",
        "\n",
        "    \\begin{align*}\n",
        "        &\\Pr(s_{h+1}=g|s_h=k,a_h=0)=0,\\\\\n",
        "        &\\Pr(s_{h+1}=g|s_h=k,a_h=1)=1,\\\\\n",
        "        &\\Pr(s_{h+1}=g|s_h=g,a_h=0)=1.\n",
        "    \\end{align*}\n",
        "    \n",
        "- Goal: maximize the probability of hiring the best candidate. Note that this goal can be written as \n",
        "    \\begin{align*}\n",
        "        \\max_{\\mu_1,\\ldots,\\mu_n} \\mathbb{E}\\left[\\sum_{h=1}^{n} r_h(s_h,\\mu_h(s_h))\\right].\n",
        "    \\end{align*}\n",
        "\n",
        "### Value Function\n",
        "\n",
        "Let $V_h(s_h)$ denote the optimal value function for state $s_h$ at stage $h$, defined by\n",
        "$$\n",
        "V_h(s_h) = \\max_{\\mu_h,\\ldots,\\mu_n} \\mathbb{E} \\left[\\sum_{k=h}^n r_k(s_k, \\mu_k(s_k))\\right].\n",
        "$$\n",
        "The optimal value function $V_h(s_h)$ can be interpreted as the probability that the best candidate will be hired under the optimal policy given $s_h$ at stage $h$. \n",
        "\n",
        "For example, let $n = 10$, $h = 5$, $s_5 = 1$. In this scenario, there are 10 candidates total. After interviewing the $5^{\\mathrm{th}}$ candidate, we know that this candidate ranks first among the 5 candidates that have been interviewed. Then $V_5(1)$ is the probability that we can successfully hire the best candidate if we follow the optimal policies at and after stage $5$.\n",
        "\n",
        "### Bellman Equation\n",
        "\n",
        "Based on the above definition and analysis, the Bellman equation for $h=1,...,n-1$ can be written as:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\begin{aligned}\n",
        "        V_h(1) =& \\max \\left\\{\\mathbb{E}[r_h(1,1)], \\mathbb{E}[V_{h+1}(s_{h+1})]\\right\\} = \\max\\left\\{\\frac{h}{n},\\frac{1}{h+1}\\sum_{s=1}^{h+1}V_{h+1}(s)\\right\\}\\\\\n",
        "        V_h(s_{h}) =& \\max \\left\\{0, \\mathbb{E}[V_{h+1}(s_{h+1})]\\right\\} = \\frac{1}{h+1}\\sum_{s=1}^{h+1}V_{h+1}(s), s_h=2,...,h.\n",
        "    \\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "For $V_h(1)$, the first term inside the maximum function, $\\mathbb{E}[r_h(1,1)]$, is the expected reward given $a_h=1$, i.e., hiring the $h^{\\mathrm{th}}$ candidate. The total future reward is 0 since the process terminates. The second term $\\mathbb{E}[V_{h+1}(s_{h+1})]$ is the expected value given $a_h=0$, i.e., rejecting the $h^{\\mathrm{th}}$ candidate, since the instantaneous reward is 0.\n",
        "\n",
        "For $V_h(s_{h})$ where $s_h=2,...,h$, the expected value for hiring the $h^{\\mathrm{th}}$ candidate is 0 since the ranking of the $h^{\\mathrm{th}}$ candidate among all the $n$ candidates must be larger than or equal to 2. Similar to the case for $V_h(1)$, the expected value of rejecting the $h^{\\mathrm{th}}$ candidate is $\\mathbb{E}[V_{h+1}(s_{h+1})]$.\n",
        "\n",
        "\n",
        "We start by calculating the optimal value function at the last stage $n$, i.e., the values of $V_n(s_n)$ for all $s_n\\in\\{1,...,n\\}$. $V_n(s_n)=1$ if $s_n=1$ and $V_n(s_n)=0$ otherwise because at stage $n$ we have interviewed all of the $n$ candidates and $s_n=1$ means that the last candidate is the best among $n$ candidates. Then we can calculate $V_h(s_h)$ for $h=n-1,\\ldots,1$ using backward search with the Bellman equation above. After obtaining the value function, we can determine the optimal policy by a forward pass.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "question_3",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "ygmGOVYD79Bg"
      },
      "source": [
        "## Codes\n",
        "\n",
        "### Backward Search\n",
        "\n",
        "We can do backward search based on the the Bellman equation and the values of $V_n(s_n)$.\n",
        "\n",
        "For the Python function `backward_cal` in the next cell, the input of the function is $n$. The output `value_function` is the value function $V_{h}(s_{h})$ for all $h\\in\\{1,\\ldots,n\\}$ and $s_h\\in\\{1,\\ldots,h\\}$. Note that we initialize the `value_function` such that its shape is $(n+1, n+1)$ and `value_function[h,s_h]` means the value function at stage $h$ and state $s_h$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HlSbnGbV79Bb"
      },
      "outputs": [],
      "source": [
        "# Import packages. Run this cell.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "question_3_code",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "IHjMRpKQ79Bg"
      },
      "outputs": [],
      "source": [
        "def backward_cal(n):\n",
        "    \"\"\"\n",
        "    Calculate the optimal value function $V_h(s_h)$ using backward seach\n",
        "    Args:\n",
        "        n: the total number of stages, n >= 2\n",
        "    Returns:\n",
        "        value_function: a numpy array with shape (n+1, n+1). value_function[h, s_h] represents $V_{h}(s_h)$.\n",
        "    \"\"\"\n",
        "    value_function = np.zeros((n + 1, n + 1))\n",
        "    value_function[n, 1] = 1\n",
        "    stage = n - 1\n",
        "    while stage >= 1:\n",
        "        for state in range(2, n + 1):\n",
        "            value_function[stage, state] = (value_function[stage + 1, 1] + value_function[stage + 1, 2] * stage) / (stage + 1)\n",
        "        value_function[stage, 1] = max(stage / n, value_function[stage, 2])\n",
        "        stage = stage - 1\n",
        "  \n",
        "    return value_function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "question_3_sample_test",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "id": "kkxMt7Bf79Bh"
      },
      "outputs": [],
      "source": [
        "# Sample Test, checking the output of the function backward_cal\n",
        "\n",
        "# Sample input\n",
        "n = 3\n",
        "\n",
        "# Sample output\n",
        "value_function = np.array([[ 0.0, 0.0, 0.0, 0.0],\n",
        "                           [ 0.0, 1/2, 0.0, 0.0],\n",
        "                           [ 0.0, 2/3, 1/3, 0.0],\n",
        "                           [ 0.0, 1.0, 0.0, 0.0]])\n",
        "\n",
        "# Sample test\n",
        "func_out = backward_cal(n)\n",
        "for h in range(1, n + 1):\n",
        "    for s_h in range(1, h + 1):\n",
        "        assert round(func_out[h, s_h], 4) == round(value_function[h, s_h], 4), \"The sample test failed.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "question_4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "52Zs_bGn79Bi"
      },
      "source": [
        "### Closed-Form Solution\n",
        "\n",
        "Consider $n\\ge 3$. Let $h^*$ be such that \n",
        "$\\frac{1}{h^*}+\\frac{1}{h^*+1}+...+\\frac{1}{n-1} \\le 1 < \\frac{1}{h^*-1}+\\frac{1}{h^*}+...+\\frac{1}{n-1}$.\n",
        "\n",
        "For example, if $n=10$, then $h^*=4$.\n",
        "\n",
        "Given $n$, $h$, and $s_h$, the value function $V_h(s_h)$ can also be calculated using the closed-form equations [1] below.\n",
        "\n",
        "For all $h^*-1 \\le h \\le n-1$,\n",
        "\n",
        "\\begin{equation}\n",
        "    \\begin{aligned}\n",
        "        V_h(1) =& \\max\\left\\{\\frac{h}{n}, \\frac{h}{n}\\left(\\frac{1}{h}+\\frac{1}{h+1}+...+\\frac{1}{n-1}\\right)\\right\\}\\\\\n",
        "        V_h(s_h) =& \\frac{h}{n}\\left(\\frac{1}{h}+\\frac{1}{h+1}+...+\\frac{1}{n-1}\\right), s_h=2,...,h\n",
        "    \\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "and for all $1 \\le h\\le h^*-1$,\n",
        "\n",
        "\\begin{align}\n",
        "    V_h(s_h) =& \\frac{h^*-1}{n}\\left(\\frac{1}{h^*-1}+\\frac{1}{h^*}+...+\\frac{1}{n-1}\\right), \\forall s_h=1,...,h.\n",
        "\\end{align}\n",
        "    \n",
        "We implemented this closed-form calculation as the Python function `V_h_closed_form`. We can verify these closed-form equations by choosing several sets of $n$, $h$, and $s_h$ as inputs and then compare the values of $V_h(s_h)$ obtained by the Python function `backward_cal` with those obtained by `V_h_closed_form`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "question_4_code_readol",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "xEKAfcrR79Bi"
      },
      "outputs": [],
      "source": [
        "def V_h_closed_form(n, h, s_h):\n",
        "    \"\"\"\n",
        "    Calculate the optimal value function $V_h(s_h)$ using the closed-form equations\n",
        "    Args:\n",
        "        n: the total number of stages\n",
        "        h: stage h\n",
        "        s_h: the state s_h at stage h\n",
        "    Returns:\n",
        "        v_h_s_h: the value of the optimal value function $V_h(s_h)$\n",
        "    \"\"\"\n",
        "    if h == n:\n",
        "        if s_h == 1:\n",
        "            v_h_s_h = 1\n",
        "        else:\n",
        "            v_h_s_h = 0\n",
        "    else:\n",
        "        for h_star in range(2, n):\n",
        "            left = sum([1 / i for i in range(h_star, n)])\n",
        "            right = left + 1 / (h_star - 1)\n",
        "            if left <= 1 and right > 1:\n",
        "                break\n",
        "        if h >= h_star:\n",
        "            if s_h == 1:\n",
        "                v_h_s_h = max(h / n, h / n * sum([1 / i for i in range(h, n)]))\n",
        "            else:\n",
        "                v_h_s_h = h / n * sum([1 / i for i in range(h, n)])\n",
        "        else:\n",
        "            v_h_s_h = (h_star - 1) / n * sum([1 / i for i in range(h_star - 1, n)])\n",
        "    \n",
        "    return v_h_s_h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "question_4_code",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true
        },
        "id": "U2g4Ydew79Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43398bcf-30a9-4cd9-9790-b301718e5ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3734471314289426 0.37344713142894265\n",
            "0.3403242717464854 0.3403242717464854\n",
            "0.55 0.55\n"
          ]
        }
      ],
      "source": [
        "# Comparison\n",
        "n = 20  # any positive integer you like\n",
        "h = 9  # any integer between 1 and n\n",
        "s_h = 2  # any integer between 1 and h\n",
        "V_h = backward_cal(n)\n",
        "print(V_h[h, s_h], V_h_closed_form(n, h, s_h))\n",
        "h = 11  # any integer between 1 and n\n",
        "s_h = 2  # any integer between 1 and h\n",
        "print(V_h[h, s_h], V_h_closed_form(n, h, s_h))\n",
        "h = 11  # any integer between 1 and n\n",
        "s_h = 1  # any integer between 1 and h\n",
        "print(V_h[h, s_h], V_h_closed_form(n, h, s_h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "question_5",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "LvNEI8cD79Bj"
      },
      "source": [
        "### Find the Optimal Policy\n",
        "\n",
        "The following function `optimal_action` will output the optimal action `a_h` given the inputs of the value function `value_function`, the number of stages `n`, stage `h` and state `s_h`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "question_5_code",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true
        },
        "id": "raGKvDdR79Bj"
      },
      "outputs": [],
      "source": [
        "def optimal_action(value_function, n, h, s_h):\n",
        "    \"\"\"\n",
        "    Calculate the optimal action $a_h$ at stage $h$\n",
        "    Args:\n",
        "        value_function: a numpy array with shape (n+1, n+1). value_function[h, s_h] represents $V_{h}(s_h)$.\n",
        "        n: the total number of stages, n >= 2\n",
        "        h: stage h\n",
        "        s_h: the state s_h at stage h\n",
        "    Returns:\n",
        "        a_h: the optimal action, 1 means hiring the candidate, 0 means rejecting the candidate\n",
        "    \"\"\"\n",
        "    a_h = None\n",
        "    if h == n:\n",
        "        a_h = 1\n",
        "    else:\n",
        "        if s_h > 1:\n",
        "            a_h = 0\n",
        "        else:\n",
        "            if h/n > (value_function[h + 1, 1] + value_function[h + 1, 2] * h) / (h + 1):\n",
        "                a_h = 1\n",
        "            else:\n",
        "                a_h = 0\n",
        "    return a_h\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Test, checking the output of the function optimal_action\n",
        "\n",
        "# Sample input\n",
        "n = 3\n",
        "value_function = backward_cal(n)\n",
        "h = 1\n",
        "s_h = 1\n",
        "\n",
        "# Sample output\n",
        "a_h = 0\n",
        "\n",
        "# Sample test\n",
        "func_out = optimal_action(value_function, n, h, s_h)\n",
        "assert func_out == a_h, \"The sample test failed.\""
      ],
      "metadata": {
        "id": "Nr86lEpkkjJb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimal Policy in Closed-Form\n",
        "\n",
        "Using the closed-form solution of the value function and the Bellman equation, we can obtain the optimal policy, that is, at stage $h$, hire the candidate if\n",
        "\n",
        "- $h\\ge h^*$, and\n",
        "- they are the best candidate so far ($s_h=1$).\n",
        "\n",
        "In other words, we reject first $h^*-1$ candidates and hire the best candidate so far after that. For large $n$, $h^* \\approx \\frac{n}{e}$ [1]."
      ],
      "metadata": {
        "id": "mhCLBtGumMPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Reference\n",
        "[1] MJ Beckmann. Dynamic programming and the secretary problem. Computers & Mathematics with Applications, 19(11):25â€“28, 1990."
      ],
      "metadata": {
        "id": "B_0i36zHolUC"
      }
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
